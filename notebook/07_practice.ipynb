{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 열과 피벗\n",
    "- 데이터프레임의 열은 파이썬 변수와 비슷한 역할을 한다.\n",
    "- 데이터프레임의 열 자체가 어떤 값을 의미한다.\n",
    "- 데이터프레임의 열이 옆으로 길게 늘어선 형태가 되는데 이것을 넓은 데이터라고 한다.\n",
    "\n",
    "# melt\n",
    "- 데이터프레임을 깔끔한 데이터로 정리하는 데 유용한 melt 메서드를 제공한다.\n",
    "- melt 메서드는 지정한 열의 데이터를 모두 행으로 정리해준다.\n",
    "\n",
    "## melt 메서드의 인자\n",
    "- id_vars : 위치를 그대로 유지할 열의 이름을 지정한다.\n",
    "- value_vars : 행으로 위치를 변경할 열의 이름을 지정한다.\n",
    "- var_name : value_vars로 위치를 변경한 열의 이름을 지정한다.\n",
    "- value_name : var_name으로 위치를 변경한 열의 데이터를 저장한 열의 이름을 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1개의 열만 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 11)\n",
      "Index(['religion', '<$10k', '$10-20k', '$20-30k', '$30-40k', '$40-50k',\n",
      "       '$50-75k', '$75-100k', '$100-150k', '>150k', 'Don't know/refused'],\n",
      "      dtype='object')\n",
      "총 열의 갯수는 :  religion              18\n",
      "<$10k                 18\n",
      "$10-20k               18\n",
      "$20-30k               18\n",
      "$30-40k               18\n",
      "$40-50k               18\n",
      "$50-75k               18\n",
      "$75-100k              18\n",
      "$100-150k             18\n",
      ">150k                 18\n",
      "Don't know/refused    18\n",
      "dtype: int64\n",
      "------------------------------------------------------------\n",
      "                  religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  \\\n",
      "0                 Agnostic     27       34       60       81       76   \n",
      "1                  Atheist     12       27       37       52       35   \n",
      "2                 Buddhist     27       21       30       34       33   \n",
      "3                 Catholic    418      617      732      670      638   \n",
      "4       Don’t know/refused     15       14       15       11       10   \n",
      "5         Evangelical Prot    575      869     1064      982      881   \n",
      "6                    Hindu      1        9        7        9       11   \n",
      "7  Historically Black Prot    228      244      236      238      197   \n",
      "8        Jehovah's Witness     20       27       24       24       21   \n",
      "9                   Jewish     19       19       25       25       30   \n",
      "\n",
      "   $50-75k  $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0      137       122        109     84                  96  \n",
      "1       70        73         59     74                  76  \n",
      "2       58        62         39     53                  54  \n",
      "3     1116       949        792    633                1489  \n",
      "4       35        21         17     18                 116  \n",
      "5     1486       949        723    414                1529  \n",
      "6       34        47         48     54                  37  \n",
      "7      223       131         81     78                 339  \n",
      "8       30        15         11      6                  37  \n",
      "9       95        69         87    151                 162  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pew = pd.read_csv('../data/pew.csv')\n",
    "print(pew.shape)\n",
    "print(pew.columns)\n",
    "print('총 열의 갯수는 : ', pew.count())\n",
    "print('-'*60)\n",
    "print(pew.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  \\\n",
      "0                  Agnostic     27       34       60       81       76   \n",
      "1                   Atheist     12       27       37       52       35   \n",
      "2                  Buddhist     27       21       30       34       33   \n",
      "3                  Catholic    418      617      732      670      638   \n",
      "4        Don’t know/refused     15       14       15       11       10   \n",
      "5          Evangelical Prot    575      869     1064      982      881   \n",
      "6                     Hindu      1        9        7        9       11   \n",
      "7   Historically Black Prot    228      244      236      238      197   \n",
      "8         Jehovah's Witness     20       27       24       24       21   \n",
      "9                    Jewish     19       19       25       25       30   \n",
      "10            Mainline Prot    289      495      619      655      651   \n",
      "\n",
      "    $50-75k  $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       137       122        109     84                  96  \n",
      "1        70        73         59     74                  76  \n",
      "2        58        62         39     53                  54  \n",
      "3      1116       949        792    633                1489  \n",
      "4        35        21         17     18                 116  \n",
      "5      1486       949        723    414                1529  \n",
      "6        34        47         48     54                  37  \n",
      "7       223       131         81     78                 339  \n",
      "8        30        15         11      6                  37  \n",
      "9        95        69         87    151                 162  \n",
      "10     1107       939        753    634                1328  \n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[0:11, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n",
      "**********************************************************************\n",
      "                  religion            variable  value\n",
      "0                 Agnostic               <$10k     27\n",
      "1                  Atheist               <$10k     12\n",
      "2                 Buddhist               <$10k     27\n",
      "3                 Catholic               <$10k    418\n",
      "4       Don’t know/refused               <$10k     15\n",
      "..                     ...                 ...    ...\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n",
      "**********************************************************************\n",
      "                   religion variable  value\n",
      "0                  Agnostic    <$10k     27\n",
      "1                   Atheist    <$10k     12\n",
      "2                  Buddhist    <$10k     27\n",
      "3                  Catholic    <$10k    418\n",
      "4        Don’t know/refused    <$10k     15\n",
      "5          Evangelical Prot    <$10k    575\n",
      "6                     Hindu    <$10k      1\n",
      "7   Historically Black Prot    <$10k    228\n",
      "8         Jehovah's Witness    <$10k     20\n",
      "9                    Jewish    <$10k     19\n",
      "10            Mainline Prot    <$10k    289\n",
      "11                   Mormon    <$10k     29\n",
      "12                   Muslim    <$10k      6\n",
      "13                 Orthodox    <$10k     13\n",
      "14          Other Christian    <$10k      9\n",
      "15             Other Faiths    <$10k     20\n",
      "16    Other World Religions    <$10k      5\n",
      "17             Unaffiliated    <$10k    217\n",
      "18                 Agnostic  $10-20k     34\n",
      "19                  Atheist  $10-20k     27\n",
      "20                 Buddhist  $10-20k     21\n",
      "21                 Catholic  $10-20k    617\n",
      "22       Don’t know/refused  $10-20k     14\n",
      "23         Evangelical Prot  $10-20k    869\n",
      "24                    Hindu  $10-20k      9\n",
      "25  Historically Black Prot  $10-20k    244\n",
      "26        Jehovah's Witness  $10-20k     27\n",
      "27                   Jewish  $10-20k     19\n",
      "28            Mainline Prot  $10-20k    495\n",
      "29                   Mormon  $10-20k     40\n"
     ]
    }
   ],
   "source": [
    "print(pew.iloc[:, 0:6])\n",
    "print('*'*70)\n",
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long)\n",
    "print('*'*70)\n",
    "print(pew_long.iloc[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=180, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(pew_long.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a1  b1  c1  d1\n",
      "1  a2  b2  c2  d2\n",
      "2  a3  b3  c3  d3\n",
      "3  a4  b4  c4  d4\n",
      "************************************************************\n",
      "     A variable value\n",
      "0   a1        B    b1\n",
      "1   a2        B    b2\n",
      "2   a3        B    b3\n",
      "3   a4        B    b4\n",
      "4   a1        C    c1\n",
      "5   a2        C    c2\n",
      "6   a3        C    c3\n",
      "7   a4        C    c4\n",
      "8   a1        D    d1\n",
      "9   a2        D    d2\n",
      "10  a3        D    d3\n",
      "11  a4        D    d4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A' : ['a1','a2','a3','a4'],\n",
    "    'B' : ['b1','b2','b3','b4'],\n",
    "    'C' : ['c1','c2','c3','c4'],\n",
    "    'D' : ['d1','d2','d3','d4'],\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "print('*'*60)\n",
    "\n",
    "print(df.melt(id_vars='A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B variable value\n",
      "0  a1  b1        C    c1\n",
      "1  a2  b2        C    c2\n",
      "2  a3  b3        C    c3\n",
      "3  a4  b4        C    c4\n",
      "4  a1  b1        D    d1\n",
      "5  a2  b2        D    d2\n",
      "6  a3  b3        D    d3\n",
      "7  a4  b4        D    d4\n",
      "************************************************************\n",
      "    A   B variable value\n",
      "0  a1  b1        C    c1\n",
      "1  a2  b2        C    c2\n",
      "2  a3  b3        C    c3\n",
      "3  a4  b4        C    c4\n",
      "************************************************************\n",
      "    A   B var_test value_test\n",
      "0  a1  b1        C         c1\n",
      "1  a2  b2        C         c2\n",
      "2  a3  b3        C         c3\n",
      "3  a4  b4        C         c4\n"
     ]
    }
   ],
   "source": [
    "print(df.melt(id_vars=['A','B']))\n",
    "print('*'*60)\n",
    "print(df.melt(id_vars=['A','B'], value_vars='C'))\n",
    "print('*'*60)\n",
    "print(df.melt(id_vars=['A','B'], value_vars='C',  var_name='var_test', value_name='value_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 81)\n",
      "************************************************************\n",
      "Index(['year', 'artist', 'track', 'time', 'date.entered', 'wk1', 'wk2', 'wk3',\n",
      "       'wk4', 'wk5', 'wk6', 'wk7', 'wk8', 'wk9', 'wk10', 'wk11', 'wk12',\n",
      "       'wk13', 'wk14', 'wk15', 'wk16', 'wk17', 'wk18', 'wk19', 'wk20', 'wk21',\n",
      "       'wk22', 'wk23', 'wk24', 'wk25', 'wk26', 'wk27', 'wk28', 'wk29', 'wk30',\n",
      "       'wk31', 'wk32', 'wk33', 'wk34', 'wk35', 'wk36', 'wk37', 'wk38', 'wk39',\n",
      "       'wk40', 'wk41', 'wk42', 'wk43', 'wk44', 'wk45', 'wk46', 'wk47', 'wk48',\n",
      "       'wk49', 'wk50', 'wk51', 'wk52', 'wk53', 'wk54', 'wk55', 'wk56', 'wk57',\n",
      "       'wk58', 'wk59', 'wk60', 'wk61', 'wk62', 'wk63', 'wk64', 'wk65', 'wk66',\n",
      "       'wk67', 'wk68', 'wk69', 'wk70', 'wk71', 'wk72', 'wk73', 'wk74', 'wk75',\n",
      "       'wk76'],\n",
      "      dtype='object')\n",
      "************************************************************\n",
      "RangeIndex(start=0, stop=317, step=1)\n",
      "************************************************************\n",
      "************************************************************\n",
      "************************************************************\n",
      "     year            artist                    track  time date.entered  wk1  \\\n",
      "0    2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87   \n",
      "1    2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91   \n",
      "2    2000      3 Doors Down               Kryptonite  3:53   2000-04-08   81   \n",
      "3    2000      3 Doors Down                    Loser  4:24   2000-10-21   76   \n",
      "4    2000          504 Boyz            Wobble Wobble  3:35   2000-04-15   57   \n",
      "..    ...               ...                      ...   ...          ...  ...   \n",
      "312  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   86   \n",
      "313  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   85   \n",
      "314  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   95   \n",
      "315  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   99   \n",
      "316  2000   matchbox twenty                     Bent  4:12   2000-04-29   60   \n",
      "\n",
      "      wk2   wk3   wk4   wk5  ...  wk67  wk68  wk69  wk70  wk71  wk72  wk73  \\\n",
      "0    82.0  72.0  77.0  87.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1    87.0  92.0   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2    70.0  68.0  67.0  66.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3    76.0  72.0  69.0  67.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4    34.0  25.0  17.0  17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "..    ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "312  83.0  77.0  74.0  83.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "313  83.0  83.0  82.0  81.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "314  94.0  91.0  85.0  84.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "315  99.0   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "316  37.0  29.0  24.0  22.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "     wk74  wk75  wk76  \n",
      "0     NaN   NaN   NaN  \n",
      "1     NaN   NaN   NaN  \n",
      "2     NaN   NaN   NaN  \n",
      "3     NaN   NaN   NaN  \n",
      "4     NaN   NaN   NaN  \n",
      "..    ...   ...   ...  \n",
      "312   NaN   NaN   NaN  \n",
      "313   NaN   NaN   NaN  \n",
      "314   NaN   NaN   NaN  \n",
      "315   NaN   NaN   NaN  \n",
      "316   NaN   NaN   NaN  \n",
      "\n",
      "[317 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "print(billboard.shape)\n",
    "print('*'*60)\n",
    "print(billboard.columns)\n",
    "print('*'*60)\n",
    "print(billboard.index)\n",
    "print('*'*60)\n",
    "print('*'*60)\n",
    "print('*'*60)\n",
    "print(billboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0  72.0  76.5  75.5  76.5   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "print(billboard.iloc[0:5, 0:16].interpolate().fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n",
      "************************************************************\n",
      "    year        artist                    track  time date.entered  week  \\\n",
      "0   2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk1   \n",
      "1   2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk1   \n",
      "2   2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk1   \n",
      "3   2000  3 Doors Down                    Loser  4:24   2000-10-21   wk1   \n",
      "4   2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk1   \n",
      "5   2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk2   \n",
      "6   2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk2   \n",
      "7   2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk2   \n",
      "8   2000  3 Doors Down                    Loser  4:24   2000-10-21   wk2   \n",
      "9   2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk2   \n",
      "10  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk3   \n",
      "11  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk3   \n",
      "12  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk3   \n",
      "13  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk3   \n",
      "14  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk3   \n",
      "15  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk4   \n",
      "16  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk4   \n",
      "17  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk4   \n",
      "18  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk4   \n",
      "19  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk4   \n",
      "20  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk5   \n",
      "21  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk5   \n",
      "22  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk5   \n",
      "23  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk5   \n",
      "24  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk5   \n",
      "25  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk6   \n",
      "26  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk6   \n",
      "27  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk6   \n",
      "28  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk6   \n",
      "29  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk6   \n",
      "30  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk7   \n",
      "31  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk7   \n",
      "32  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk7   \n",
      "33  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk7   \n",
      "34  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk7   \n",
      "35  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk8   \n",
      "36  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk8   \n",
      "37  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk8   \n",
      "38  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk8   \n",
      "39  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk8   \n",
      "40  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   wk9   \n",
      "41  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   wk9   \n",
      "42  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   wk9   \n",
      "43  2000  3 Doors Down                    Loser  4:24   2000-10-21   wk9   \n",
      "44  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   wk9   \n",
      "45  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk10   \n",
      "46  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk10   \n",
      "47  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk10   \n",
      "48  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk10   \n",
      "49  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk10   \n",
      "50  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk11   \n",
      "51  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk11   \n",
      "52  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk11   \n",
      "53  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk11   \n",
      "54  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk11   \n",
      "\n",
      "    rating  \n",
      "0     87.0  \n",
      "1     91.0  \n",
      "2     81.0  \n",
      "3     76.0  \n",
      "4     57.0  \n",
      "5     82.0  \n",
      "6     87.0  \n",
      "7     70.0  \n",
      "8     76.0  \n",
      "9     34.0  \n",
      "10    72.0  \n",
      "11    92.0  \n",
      "12    68.0  \n",
      "13    72.0  \n",
      "14    25.0  \n",
      "15    77.0  \n",
      "16     NaN  \n",
      "17    67.0  \n",
      "18    69.0  \n",
      "19    17.0  \n",
      "20    87.0  \n",
      "21     NaN  \n",
      "22    66.0  \n",
      "23    67.0  \n",
      "24    17.0  \n",
      "25    94.0  \n",
      "26     NaN  \n",
      "27    57.0  \n",
      "28    65.0  \n",
      "29    31.0  \n",
      "30    99.0  \n",
      "31     NaN  \n",
      "32    54.0  \n",
      "33    55.0  \n",
      "34    36.0  \n",
      "35     NaN  \n",
      "36     NaN  \n",
      "37    53.0  \n",
      "38    59.0  \n",
      "39    49.0  \n",
      "40     NaN  \n",
      "41     NaN  \n",
      "42    51.0  \n",
      "43    62.0  \n",
      "44    53.0  \n",
      "45     NaN  \n",
      "46     NaN  \n",
      "47    51.0  \n",
      "48    61.0  \n",
      "49    57.0  \n",
      "50     NaN  \n",
      "51     NaN  \n",
      "52    51.0  \n",
      "53    61.0  \n",
      "54    64.0  \n"
     ]
    }
   ],
   "source": [
    "print(billboard.iloc[0:5, 0:16])\n",
    "print('*'*60)\n",
    "print(billboard.iloc[0:5, 0:16].melt(id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "billboard_long = billboard.iloc[0:5, 0:16].melt(id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ebola 데이터 집합 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n",
      "           Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \\\n",
      "0      1/5/2015  289        2776.0            NaN            10030.0   \n",
      "1      1/4/2015  288        2775.0            NaN             9780.0   \n",
      "2      1/3/2015  287        2769.0         8166.0             9722.0   \n",
      "3      1/2/2015  286           NaN         8157.0                NaN   \n",
      "4    12/31/2014  284        2730.0         8115.0             9633.0   \n",
      "..          ...  ...           ...            ...                ...   \n",
      "117   3/27/2014    5         103.0            8.0                6.0   \n",
      "118   3/26/2014    4          86.0            NaN                NaN   \n",
      "119   3/25/2014    3          86.0            NaN                NaN   \n",
      "120   3/24/2014    2          86.0            NaN                NaN   \n",
      "121   3/22/2014    0          49.0            NaN                NaN   \n",
      "\n",
      "     Cases_Nigeria  Cases_Senegal  Cases_UnitedStates  Cases_Spain  \\\n",
      "0              NaN            NaN                 NaN          NaN   \n",
      "1              NaN            NaN                 NaN          NaN   \n",
      "2              NaN            NaN                 NaN          NaN   \n",
      "3              NaN            NaN                 NaN          NaN   \n",
      "4              NaN            NaN                 NaN          NaN   \n",
      "..             ...            ...                 ...          ...   \n",
      "117            NaN            NaN                 NaN          NaN   \n",
      "118            NaN            NaN                 NaN          NaN   \n",
      "119            NaN            NaN                 NaN          NaN   \n",
      "120            NaN            NaN                 NaN          NaN   \n",
      "121            NaN            NaN                 NaN          NaN   \n",
      "\n",
      "     Cases_Mali  Deaths_Guinea  Deaths_Liberia  Deaths_SierraLeone  \\\n",
      "0           NaN         1786.0             NaN              2977.0   \n",
      "1           NaN         1781.0             NaN              2943.0   \n",
      "2           NaN         1767.0          3496.0              2915.0   \n",
      "3           NaN            NaN          3496.0                 NaN   \n",
      "4           NaN         1739.0          3471.0              2827.0   \n",
      "..          ...            ...             ...                 ...   \n",
      "117         NaN           66.0             6.0                 5.0   \n",
      "118         NaN           62.0             NaN                 NaN   \n",
      "119         NaN           60.0             NaN                 NaN   \n",
      "120         NaN           59.0             NaN                 NaN   \n",
      "121         NaN           29.0             NaN                 NaN   \n",
      "\n",
      "     Deaths_Nigeria  Deaths_Senegal  Deaths_UnitedStates  Deaths_Spain  \\\n",
      "0               NaN             NaN                  NaN           NaN   \n",
      "1               NaN             NaN                  NaN           NaN   \n",
      "2               NaN             NaN                  NaN           NaN   \n",
      "3               NaN             NaN                  NaN           NaN   \n",
      "4               NaN             NaN                  NaN           NaN   \n",
      "..              ...             ...                  ...           ...   \n",
      "117             NaN             NaN                  NaN           NaN   \n",
      "118             NaN             NaN                  NaN           NaN   \n",
      "119             NaN             NaN                  NaN           NaN   \n",
      "120             NaN             NaN                  NaN           NaN   \n",
      "121             NaN             NaN                  NaN           NaN   \n",
      "\n",
      "     Deaths_Mali  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "..           ...  \n",
      "117          NaN  \n",
      "118          NaN  \n",
      "119          NaN  \n",
      "120          NaN  \n",
      "121          NaN  \n",
      "\n",
      "[122 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('../data/country_timeseries.csv')\n",
    "print(ebola.columns)\n",
    "print(ebola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5,[0,1,2,3,10,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 열 이름 나누고 데이터 프레임에 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split 메서드로 열 이름 분리하기\n",
    "- split메서드에 나누고 싶은 문자를 넣어주면 분리가 가능해진다.\n",
    "- ex) Cases_Guinea를 split에 '-'을 인자값으로 전달하면 Cases와 Guinea로 분리가 된다.\n",
    "- Series.str.split('_')이런 식으로 시리즈는 문자를 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'variable', 'value'], dtype='object')\n",
      "0       [Cases, Guinea]\n",
      "1       [Cases, Guinea]\n",
      "2       [Cases, Guinea]\n",
      "3       [Cases, Guinea]\n",
      "4       [Cases, Guinea]\n",
      "             ...       \n",
      "1947     [Deaths, Mali]\n",
      "1948     [Deaths, Mali]\n",
      "1949     [Deaths, Mali]\n",
      "1950     [Deaths, Mali]\n",
      "1951     [Deaths, Mali]\n",
      "Name: variable, Length: 1952, dtype: object\n",
      "************************************************************\n",
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola_long.columns)\n",
    "variable_split = ebola_long['variable'].str.split('_')\n",
    "print(variable_split)\n",
    "print('*'*60)\n",
    "print(ebola_long[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0       [Cases, Guinea]\n",
      "1       [Cases, Guinea]\n",
      "2       [Cases, Guinea]\n",
      "3       [Cases, Guinea]\n",
      "4       [Cases, Guinea]\n",
      "             ...       \n",
      "1947     [Deaths, Mali]\n",
      "1948     [Deaths, Mali]\n",
      "1949     [Deaths, Mali]\n",
      "1950     [Deaths, Mali]\n",
      "1951     [Deaths, Mali]\n",
      "Name: variable, Length: 1952, dtype: object\n",
      "************************************************************\n",
      "<class 'list'>\n",
      "['Cases', 'Guinea']\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split))\n",
    "print(variable_split)\n",
    "print('**'*30)\n",
    "print(type(variable_split[0]))\n",
    "print(variable_split[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series.str.get(0)\n",
    "- get메서드를 이용하여 0, 1번째등의 값을 추출하는 방법을 알아본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Cases\n",
      "1        Cases\n",
      "2        Cases\n",
      "3        Cases\n",
      "4        Cases\n",
      "         ...  \n",
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, Length: 1952, dtype: object\n",
      "------------------------------------------------------------\n",
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n",
      "------------------------------------------------------------\n",
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "status_variable= variable_split.str.get(0)\n",
    "print(status_variable)\n",
    "print('-'*60)\n",
    "print(status_variable[:5])\n",
    "print('-'*60)\n",
    "print(status_variable[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Guinea\n",
      "1       Guinea\n",
      "2       Guinea\n",
      "3       Guinea\n",
      "4       Guinea\n",
      "         ...  \n",
      "1947      Mali\n",
      "1948      Mali\n",
      "1949      Mali\n",
      "1950      Mali\n",
      "1951      Mali\n",
      "Name: variable, Length: 1952, dtype: object\n",
      "------------------------------------------------------------\n",
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n",
      "------------------------------------------------------------\n",
      "1947    Mali\n",
      "1948    Mali\n",
      "1949    Mali\n",
      "1950    Mali\n",
      "1951    Mali\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "country_variable = variable_split.str.get(1)\n",
    "print(country_variable)\n",
    "print('-'*60)\n",
    "print(country_variable[:5])\n",
    "print('-'*60)\n",
    "print(country_variable[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value  status country\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0   Cases  Guinea\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0   Cases  Guinea\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0   Cases  Guinea\n",
      "3       1/2/2015  286  Cases_Guinea     NaN   Cases  Guinea\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0   Cases  Guinea\n",
      "...          ...  ...           ...     ...     ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN  Deaths    Mali\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN  Deaths    Mali\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN  Deaths    Mali\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN  Deaths    Mali\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN  Deaths    Mali\n",
      "\n",
      "[1952 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "ebola_long['status'] = status_variable\n",
    "ebola_long['country'] = country_variable\n",
    "print(ebola_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드를 응용하여 데이터프레임에 열 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# str.split('-', expand=True)\n",
    "- expand : 분할된 문자열을 별도의 열로 확장한다.\n",
    "- True이면 차원 확장 DataFrame/MultiIndex를 반환합니다.\n",
    "- False이면 문자열 목록이 포함된 Series/Index를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat을 이용하면 더욱 더 간단하게 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1\n",
      "0  Cases  Guinea\n",
      "1  Cases  Guinea\n",
      "2  Cases  Guinea\n",
      "3  Cases  Guinea\n",
      "4  Cases  Guinea\n",
      "  status country\n",
      "0  Cases  Guinea\n",
      "1  Cases  Guinea\n",
      "2  Cases  Guinea\n",
      "3  Cases  Guinea\n",
      "4  Cases  Guinea\n",
      "************************************************************\n",
      "            Date  Day      variable   value  status country  status country\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0   Cases  Guinea   Cases  Guinea\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0   Cases  Guinea   Cases  Guinea\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0   Cases  Guinea   Cases  Guinea\n",
      "3       1/2/2015  286  Cases_Guinea     NaN   Cases  Guinea   Cases  Guinea\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0   Cases  Guinea   Cases  Guinea\n",
      "...          ...  ...           ...     ...     ...     ...     ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN  Deaths    Mali  Deaths    Mali\n",
      "\n",
      "[1952 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "variable_split = ebola_long.variable.str.split('_', expand=True)\n",
    "print(variable_split.head())\n",
    "variable_split.columns = ['status', 'country']\n",
    "print(variable_split.head())\n",
    "print('*'*60)\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "print(ebola_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기상 데이터의 여러 열을 하나로 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  ...  d22   d23  \\\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN  ...  NaN  29.9   \n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN  ...  NaN  10.7   \n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN  ...  NaN   NaN   \n",
      "\n",
      "   d24  d25  d26  d27  d28  d29   d30  d31  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  27.8  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  14.5  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv('../data/weather.csv')\n",
    "print(weather.iloc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'], var_name='day', value_name='temp')\n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pivot_table 메서드\n",
    " - 행과 열의 위치를 다시 바꿔 정리해준다.\n",
    " - index 인자에는 위치를 그대로 유지할 열 이름을 지정한다.\n",
    " - columns 인자에는 피벗할 열 이름을 지정한다.\n",
    " - values value에 채우고자 하는 컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d1    NaN   NaN\n",
      "                   d10   NaN   NaN\n",
      "                   d11   NaN   NaN\n",
      "                   d12   NaN   NaN\n",
      "                   d13   NaN   NaN\n",
      "...                      ...   ...\n",
      "             12    d5    NaN   NaN\n",
      "                   d6   27.8  10.5\n",
      "                   d7    NaN   NaN\n",
      "                   d8    NaN   NaN\n",
      "                   d9    NaN   NaN\n",
      "\n",
      "[341 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index = ['id', 'year', 'month', 'day'],\n",
    "    columns = 'element',\n",
    "    values = 'temp',\n",
    "    dropna = False\n",
    ")\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reset_index 메서드를 이용하여 인덱스 새로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1   d1   NaN   NaN\n",
      "1        MX17004  2010      1  d10   NaN   NaN\n",
      "2        MX17004  2010      1  d11   NaN   NaN\n",
      "3        MX17004  2010      1  d12   NaN   NaN\n",
      "4        MX17004  2010      1  d13   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빌보드 차트의 중복 데이터 처리하기 (drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year            artist                    track  time date.entered  wk1  \\\n",
      "0    2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87   \n",
      "1    2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91   \n",
      "2    2000      3 Doors Down               Kryptonite  3:53   2000-04-08   81   \n",
      "3    2000      3 Doors Down                    Loser  4:24   2000-10-21   76   \n",
      "4    2000          504 Boyz            Wobble Wobble  3:35   2000-04-15   57   \n",
      "..    ...               ...                      ...   ...          ...  ...   \n",
      "312  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   86   \n",
      "313  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   85   \n",
      "314  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   95   \n",
      "315  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   99   \n",
      "316  2000   matchbox twenty                     Bent  4:12   2000-04-29   60   \n",
      "\n",
      "      wk2   wk3   wk4   wk5  ...  wk67  wk68  wk69  wk70  wk71  wk72  wk73  \\\n",
      "0    82.0  72.0  77.0  87.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1    87.0  92.0   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "2    70.0  68.0  67.0  66.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "3    76.0  72.0  69.0  67.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "4    34.0  25.0  17.0  17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "..    ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "312  83.0  77.0  74.0  83.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "313  83.0  83.0  82.0  81.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "314  94.0  91.0  85.0  84.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "315  99.0   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "316  37.0  29.0  24.0  22.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "     wk74  wk75  wk76  \n",
      "0     NaN   NaN   NaN  \n",
      "1     NaN   NaN   NaN  \n",
      "2     NaN   NaN   NaN  \n",
      "3     NaN   NaN   NaN  \n",
      "4     NaN   NaN   NaN  \n",
      "..    ...   ...   ...  \n",
      "312   NaN   NaN   NaN  \n",
      "313   NaN   NaN   NaN  \n",
      "314   NaN   NaN   NaN  \n",
      "315   NaN   NaN   NaN  \n",
      "316   NaN   NaN   NaN  \n",
      "\n",
      "[317 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "print(billboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year            artist                    track  time date.entered  \\\n",
      "0      2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "1      2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   \n",
      "2      2000      3 Doors Down               Kryptonite  3:53   2000-04-08   \n",
      "3      2000      3 Doors Down                    Loser  4:24   2000-10-21   \n",
      "4      2000          504 Boyz            Wobble Wobble  3:35   2000-04-15   \n",
      "...     ...               ...                      ...   ...          ...   \n",
      "24087  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   \n",
      "24088  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   \n",
      "24089  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   \n",
      "24090  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   \n",
      "24091  2000   matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating  \n",
      "0       wk1    87.0  \n",
      "1       wk1    91.0  \n",
      "2       wk1    81.0  \n",
      "3       wk1    76.0  \n",
      "4       wk1    57.0  \n",
      "...     ...     ...  \n",
      "24087  wk76     NaN  \n",
      "24088  wk76     NaN  \n",
      "24089  wk76     NaN  \n",
      "24090  wk76     NaN  \n",
      "24091  wk76     NaN  \n",
      "\n",
      "[24092 rows x 7 columns]\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n",
      "(24092, 7)\n"
     ]
    }
   ],
   "source": [
    "billboard_melt = billboard.melt(id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "print(billboard_melt)\n",
    "print(billboard_melt.head())\n",
    "print(billboard_melt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_melt[billboard_melt['track'] == 'Loser'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'artist', 'track', 'time', 'date.entered', 'week', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(billboard_melt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복데이터가 가지고 있는 열은 year, artist, track, time, date이다.\n",
    "### 이 열을 따로 모아 새로운 데이터 프레임을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year            artist                    track  time date.entered\n",
      "0      2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26\n",
      "1      2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02\n",
      "2      2000      3 Doors Down               Kryptonite  3:53   2000-04-08\n",
      "3      2000      3 Doors Down                    Loser  4:24   2000-10-21\n",
      "4      2000          504 Boyz            Wobble Wobble  3:35   2000-04-15\n",
      "...     ...               ...                      ...   ...          ...\n",
      "24087  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29\n",
      "24088  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01\n",
      "24089  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18\n",
      "24090  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02\n",
      "24091  2000   matchbox twenty                     Bent  4:12   2000-04-29\n",
      "\n",
      "[24092 rows x 5 columns]\n",
      "(24092, 5)\n"
     ]
    }
   ],
   "source": [
    "billboard_dup = billboard_melt[['year', 'artist', 'track', 'time', 'date.entered']]\n",
    "print(billboard_dup)\n",
    "print(billboard_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year            artist                    track  time date.entered\n",
      "0    2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26\n",
      "1    2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02\n",
      "2    2000      3 Doors Down               Kryptonite  3:53   2000-04-08\n",
      "3    2000      3 Doors Down                    Loser  4:24   2000-10-21\n",
      "4    2000          504 Boyz            Wobble Wobble  3:35   2000-04-15\n",
      "..    ...               ...                      ...   ...          ...\n",
      "312  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29\n",
      "313  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01\n",
      "314  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18\n",
      "315  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02\n",
      "316  2000   matchbox twenty                     Bent  4:12   2000-04-29\n",
      "\n",
      "[317 rows x 5 columns]\n",
      "(317, 5)\n"
     ]
    }
   ],
   "source": [
    "billboard_dup = billboard_dup.drop_duplicates()\n",
    "print(billboard_dup)\n",
    "print(billboard_dup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복을 제거한 데이터프레임에 id도 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year            artist                    track  time date.entered   id\n",
      "0    2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26    0\n",
      "1    2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02    1\n",
      "2    2000      3 Doors Down               Kryptonite  3:53   2000-04-08    2\n",
      "3    2000      3 Doors Down                    Loser  4:24   2000-10-21    3\n",
      "4    2000          504 Boyz            Wobble Wobble  3:35   2000-04-15    4\n",
      "..    ...               ...                      ...   ...          ...  ...\n",
      "312  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29  312\n",
      "313  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01  313\n",
      "314  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18  314\n",
      "315  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02  315\n",
      "316  2000   matchbox twenty                     Bent  4:12   2000-04-29  316\n",
      "\n",
      "[317 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "billboard_dup['id'] = range(len(billboard_dup))\n",
    "print(billboard_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.request.urlretrieve(url, 저장할 파일 경로)\n",
    "- urllib : Http,Ftp 프로토콜을 통해서 다운받고 사용할수 있게 도와주는 라이브러리\n",
    "\n",
    "- request모듈: 웹사이트에 있는 데이터에 접근하게 해주는 모듈\n",
    "\n",
    "- urlretrieve함수: 웹상에 자료를 다운로드 할수 있게 도와주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴욕 택시 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path.join(dir_path, file name)으로 인자를 전달하면 디렉토리 경로에 파일 이름을 조합하고 그 path를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url :  https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "fp :  ../data\\fhv_tripdata_2015-01.csv\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl : \u001b[39m\u001b[38;5;124m'\u001b[39m,url)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp : \u001b[39m\u001b[38;5;124m'\u001b[39m, fp)\n\u001b[1;32m---> 12\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    240\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('','../data',fn)\n",
    "        print('url : ',url)\n",
    "        print('fp : ', fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn fhv_tripdata_2015-01.csv\n",
      "fp ../data\\fhv_tripdata_2015-01.csv\n",
      "fn fhv_tripdata_2015-02.csv\n",
      "fp ../data\\fhv_tripdata_2015-02.csv\n",
      "fn fhv_tripdata_2015-03.csv\n",
      "fp ../data\\fhv_tripdata_2015-03.csv\n",
      "fn fhv_tripdata_2015-04.csv\n",
      "fp ../data\\fhv_tripdata_2015-04.csv\n",
      "fn fhv_tripdata_2015-05.csv\n",
      "fp ../data\\fhv_tripdata_2015-05.csv\n",
      "fn fhv_tripdata_2015-06.csv\n",
      "fp ../data\\fhv_tripdata_2015-06.csv\n",
      "fn fhv_tripdata_2015-07.csv\n",
      "fp ../data\\fhv_tripdata_2015-07.csv\n",
      "fn fhv_tripdata_2015-08.csv\n",
      "fp ../data\\fhv_tripdata_2015-08.csv\n",
      "fn fhv_tripdata_2015-09.csv\n",
      "fp ../data\\fhv_tripdata_2015-09.csv\n",
      "fn fhv_tripdata_2015-10.csv\n",
      "fp ../data\\fhv_tripdata_2015-10.csv\n",
      "fn fhv_tripdata_2015-11.csv\n",
      "fp ../data\\fhv_tripdata_2015-11.csv\n",
      "fn fhv_tripdata_2015-12.csv\n",
      "fp ../data\\fhv_tripdata_2015-12.csv\n",
      "fn fhv_tripdata_2016-01.csv\n",
      "fp ../data\\fhv_tripdata_2016-01.csv\n",
      "fn fhv_tripdata_2016-02.csv\n",
      "fp ../data\\fhv_tripdata_2016-02.csv\n",
      "fn fhv_tripdata_2016-03.csv\n",
      "fp ../data\\fhv_tripdata_2016-03.csv\n",
      "fn fhv_tripdata_2016-04.csv\n",
      "fp ../data\\fhv_tripdata_2016-04.csv\n",
      "fn fhv_tripdata_2016-05.csv\n",
      "fp ../data\\fhv_tripdata_2016-05.csv\n",
      "fn fhv_tripdata_2016-06.csv\n",
      "fp ../data\\fhv_tripdata_2016-06.csv\n",
      "fn fhv_tripdata_2016-07.csv\n",
      "fp ../data\\fhv_tripdata_2016-07.csv\n",
      "fn fhv_tripdata_2016-08.csv\n",
      "fp ../data\\fhv_tripdata_2016-08.csv\n",
      "fn fhv_tripdata_2016-09.csv\n",
      "fp ../data\\fhv_tripdata_2016-09.csv\n",
      "fn fhv_tripdata_2016-10.csv\n",
      "fp ../data\\fhv_tripdata_2016-10.csv\n",
      "fn fhv_tripdata_2016-11.csv\n",
      "fp ../data\\fhv_tripdata_2016-11.csv\n",
      "fn fhv_tripdata_2016-12.csv\n",
      "fp ../data\\fhv_tripdata_2016-12.csv\n",
      "fn green_tripdata_2013-08.csv\n",
      "fp ../data\\green_tripdata_2013-08.csv\n",
      "fn green_tripdata_2013-09.csv\n",
      "fp ../data\\green_tripdata_2013-09.csv\n",
      "fn green_tripdata_2013-10.csv\n",
      "fp ../data\\green_tripdata_2013-10.csv\n",
      "fn green_tripdata_2013-11.csv\n",
      "fp ../data\\green_tripdata_2013-11.csv\n",
      "fn green_tripdata_2013-12.csv\n",
      "fp ../data\\green_tripdata_2013-12.csv\n",
      "fn green_tripdata_2014-01.csv\n",
      "fp ../data\\green_tripdata_2014-01.csv\n",
      "fn green_tripdata_2014-02.csv\n",
      "fp ../data\\green_tripdata_2014-02.csv\n",
      "fn green_tripdata_2014-03.csv\n",
      "fp ../data\\green_tripdata_2014-03.csv\n",
      "fn green_tripdata_2014-04.csv\n",
      "fp ../data\\green_tripdata_2014-04.csv\n",
      "fn green_tripdata_2014-05.csv\n",
      "fp ../data\\green_tripdata_2014-05.csv\n",
      "fn green_tripdata_2014-06.csv\n",
      "fp ../data\\green_tripdata_2014-06.csv\n",
      "fn green_tripdata_2014-07.csv\n",
      "fp ../data\\green_tripdata_2014-07.csv\n",
      "fn green_tripdata_2014-08.csv\n",
      "fp ../data\\green_tripdata_2014-08.csv\n",
      "fn green_tripdata_2014-09.csv\n",
      "fp ../data\\green_tripdata_2014-09.csv\n",
      "fn green_tripdata_2014-10.csv\n",
      "fp ../data\\green_tripdata_2014-10.csv\n",
      "fn green_tripdata_2014-11.csv\n",
      "fp ../data\\green_tripdata_2014-11.csv\n",
      "fn green_tripdata_2014-12.csv\n",
      "fp ../data\\green_tripdata_2014-12.csv\n",
      "fn green_tripdata_2015-01.csv\n",
      "fp ../data\\green_tripdata_2015-01.csv\n",
      "fn green_tripdata_2015-02.csv\n",
      "fp ../data\\green_tripdata_2015-02.csv\n",
      "fn green_tripdata_2015-03.csv\n",
      "fp ../data\\green_tripdata_2015-03.csv\n",
      "fn green_tripdata_2015-04.csv\n",
      "fp ../data\\green_tripdata_2015-04.csv\n",
      "fn green_tripdata_2015-05.csv\n",
      "fp ../data\\green_tripdata_2015-05.csv\n",
      "fn green_tripdata_2015-06.csv\n",
      "fp ../data\\green_tripdata_2015-06.csv\n",
      "fn green_tripdata_2015-07.csv\n",
      "fp ../data\\green_tripdata_2015-07.csv\n",
      "fn green_tripdata_2015-08.csv\n",
      "fp ../data\\green_tripdata_2015-08.csv\n",
      "fn green_tripdata_2015-09.csv\n",
      "fp ../data\\green_tripdata_2015-09.csv\n",
      "fn green_tripdata_2015-10.csv\n",
      "fp ../data\\green_tripdata_2015-10.csv\n",
      "fn green_tripdata_2015-11.csv\n",
      "fp ../data\\green_tripdata_2015-11.csv\n",
      "fn green_tripdata_2015-12.csv\n",
      "fp ../data\\green_tripdata_2015-12.csv\n",
      "fn green_tripdata_2016-01.csv\n",
      "fp ../data\\green_tripdata_2016-01.csv\n",
      "fn green_tripdata_2016-02.csv\n",
      "fp ../data\\green_tripdata_2016-02.csv\n",
      "fn green_tripdata_2016-03.csv\n",
      "fp ../data\\green_tripdata_2016-03.csv\n",
      "fn green_tripdata_2016-04.csv\n",
      "fp ../data\\green_tripdata_2016-04.csv\n",
      "fn green_tripdata_2016-05.csv\n",
      "fp ../data\\green_tripdata_2016-05.csv\n",
      "fn green_tripdata_2016-06.csv\n",
      "fp ../data\\green_tripdata_2016-06.csv\n",
      "fn green_tripdata_2016-07.csv\n",
      "fp ../data\\green_tripdata_2016-07.csv\n",
      "fn green_tripdata_2016-08.csv\n",
      "fp ../data\\green_tripdata_2016-08.csv\n",
      "fn green_tripdata_2016-09.csv\n",
      "fp ../data\\green_tripdata_2016-09.csv\n",
      "fn green_tripdata_2016-10.csv\n",
      "fp ../data\\green_tripdata_2016-10.csv\n",
      "fn green_tripdata_2016-11.csv\n",
      "fp ../data\\green_tripdata_2016-11.csv\n",
      "fn green_tripdata_2016-12.csv\n",
      "fp ../data\\green_tripdata_2016-12.csv\n",
      "fn yellow_tripdata_2009-01.csv\n",
      "fp ../data\\yellow_tripdata_2009-01.csv\n",
      "fn yellow_tripdata_2009-02.csv\n",
      "fp ../data\\yellow_tripdata_2009-02.csv\n",
      "fn yellow_tripdata_2009-03.csv\n",
      "fp ../data\\yellow_tripdata_2009-03.csv\n",
      "fn yellow_tripdata_2009-04.csv\n",
      "fp ../data\\yellow_tripdata_2009-04.csv\n",
      "fn yellow_tripdata_2009-05.csv\n",
      "fp ../data\\yellow_tripdata_2009-05.csv\n",
      "fn yellow_tripdata_2009-06.csv\n",
      "fp ../data\\yellow_tripdata_2009-06.csv\n",
      "fn yellow_tripdata_2009-07.csv\n",
      "fp ../data\\yellow_tripdata_2009-07.csv\n",
      "fn yellow_tripdata_2009-08.csv\n",
      "fp ../data\\yellow_tripdata_2009-08.csv\n",
      "fn yellow_tripdata_2009-09.csv\n",
      "fp ../data\\yellow_tripdata_2009-09.csv\n",
      "fn yellow_tripdata_2009-10.csv\n",
      "fp ../data\\yellow_tripdata_2009-10.csv\n",
      "fn yellow_tripdata_2009-11.csv\n",
      "fp ../data\\yellow_tripdata_2009-11.csv\n",
      "fn yellow_tripdata_2009-12.csv\n",
      "fp ../data\\yellow_tripdata_2009-12.csv\n",
      "fn yellow_tripdata_2010-01.csv\n",
      "fp ../data\\yellow_tripdata_2010-01.csv\n",
      "fn yellow_tripdata_2010-02.csv\n",
      "fp ../data\\yellow_tripdata_2010-02.csv\n",
      "fn yellow_tripdata_2010-03.csv\n",
      "fp ../data\\yellow_tripdata_2010-03.csv\n",
      "fn yellow_tripdata_2010-04.csv\n",
      "fp ../data\\yellow_tripdata_2010-04.csv\n",
      "fn yellow_tripdata_2010-05.csv\n",
      "fp ../data\\yellow_tripdata_2010-05.csv\n",
      "fn yellow_tripdata_2010-06.csv\n",
      "fp ../data\\yellow_tripdata_2010-06.csv\n",
      "fn yellow_tripdata_2010-07.csv\n",
      "fp ../data\\yellow_tripdata_2010-07.csv\n",
      "fn yellow_tripdata_2010-08.csv\n",
      "fp ../data\\yellow_tripdata_2010-08.csv\n",
      "fn yellow_tripdata_2010-09.csv\n",
      "fp ../data\\yellow_tripdata_2010-09.csv\n",
      "fn yellow_tripdata_2010-10.csv\n",
      "fp ../data\\yellow_tripdata_2010-10.csv\n",
      "fn yellow_tripdata_2010-11.csv\n",
      "fp ../data\\yellow_tripdata_2010-11.csv\n",
      "fn yellow_tripdata_2010-12.csv\n",
      "fp ../data\\yellow_tripdata_2010-12.csv\n",
      "fn yellow_tripdata_2011-01.csv\n",
      "fp ../data\\yellow_tripdata_2011-01.csv\n",
      "fn yellow_tripdata_2011-02.csv\n",
      "fp ../data\\yellow_tripdata_2011-02.csv\n",
      "fn yellow_tripdata_2011-03.csv\n",
      "fp ../data\\yellow_tripdata_2011-03.csv\n",
      "fn yellow_tripdata_2011-04.csv\n",
      "fp ../data\\yellow_tripdata_2011-04.csv\n",
      "fn yellow_tripdata_2011-05.csv\n",
      "fp ../data\\yellow_tripdata_2011-05.csv\n",
      "fn yellow_tripdata_2011-06.csv\n",
      "fp ../data\\yellow_tripdata_2011-06.csv\n",
      "fn yellow_tripdata_2011-07.csv\n",
      "fp ../data\\yellow_tripdata_2011-07.csv\n",
      "fn yellow_tripdata_2011-08.csv\n",
      "fp ../data\\yellow_tripdata_2011-08.csv\n",
      "fn yellow_tripdata_2011-09.csv\n",
      "fp ../data\\yellow_tripdata_2011-09.csv\n",
      "fn yellow_tripdata_2011-10.csv\n",
      "fp ../data\\yellow_tripdata_2011-10.csv\n",
      "fn yellow_tripdata_2011-11.csv\n",
      "fp ../data\\yellow_tripdata_2011-11.csv\n",
      "fn yellow_tripdata_2011-12.csv\n",
      "fp ../data\\yellow_tripdata_2011-12.csv\n",
      "fn yellow_tripdata_2012-01.csv\n",
      "fp ../data\\yellow_tripdata_2012-01.csv\n",
      "fn yellow_tripdata_2012-02.csv\n",
      "fp ../data\\yellow_tripdata_2012-02.csv\n",
      "fn yellow_tripdata_2012-03.csv\n",
      "fp ../data\\yellow_tripdata_2012-03.csv\n",
      "fn yellow_tripdata_2012-04.csv\n",
      "fp ../data\\yellow_tripdata_2012-04.csv\n",
      "fn yellow_tripdata_2012-05.csv\n",
      "fp ../data\\yellow_tripdata_2012-05.csv\n",
      "fn yellow_tripdata_2012-06.csv\n",
      "fp ../data\\yellow_tripdata_2012-06.csv\n",
      "fn yellow_tripdata_2012-07.csv\n",
      "fp ../data\\yellow_tripdata_2012-07.csv\n",
      "fn yellow_tripdata_2012-08.csv\n",
      "fp ../data\\yellow_tripdata_2012-08.csv\n",
      "fn yellow_tripdata_2012-09.csv\n",
      "fp ../data\\yellow_tripdata_2012-09.csv\n",
      "fn yellow_tripdata_2012-10.csv\n",
      "fp ../data\\yellow_tripdata_2012-10.csv\n",
      "fn yellow_tripdata_2012-11.csv\n",
      "fp ../data\\yellow_tripdata_2012-11.csv\n",
      "fn yellow_tripdata_2012-12.csv\n",
      "fp ../data\\yellow_tripdata_2012-12.csv\n",
      "fn yellow_tripdata_2013-01.csv\n",
      "fp ../data\\yellow_tripdata_2013-01.csv\n",
      "fn yellow_tripdata_2013-02.csv\n",
      "fp ../data\\yellow_tripdata_2013-02.csv\n",
      "fn yellow_tripdata_2013-03.csv\n",
      "fp ../data\\yellow_tripdata_2013-03.csv\n",
      "fn yellow_tripdata_2013-04.csv\n",
      "fp ../data\\yellow_tripdata_2013-04.csv\n",
      "fn yellow_tripdata_2013-05.csv\n",
      "fp ../data\\yellow_tripdata_2013-05.csv\n",
      "fn yellow_tripdata_2013-06.csv\n",
      "fp ../data\\yellow_tripdata_2013-06.csv\n",
      "fn yellow_tripdata_2013-07.csv\n",
      "fp ../data\\yellow_tripdata_2013-07.csv\n",
      "fn yellow_tripdata_2013-08.csv\n",
      "fp ../data\\yellow_tripdata_2013-08.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn yellow_tripdata_2013-09.csv\n",
      "fp ../data\\yellow_tripdata_2013-09.csv\n",
      "fn yellow_tripdata_2013-10.csv\n",
      "fp ../data\\yellow_tripdata_2013-10.csv\n",
      "fn yellow_tripdata_2013-11.csv\n",
      "fp ../data\\yellow_tripdata_2013-11.csv\n",
      "fn yellow_tripdata_2013-12.csv\n",
      "fp ../data\\yellow_tripdata_2013-12.csv\n",
      "fn yellow_tripdata_2014-01.csv\n",
      "fp ../data\\yellow_tripdata_2014-01.csv\n",
      "fn yellow_tripdata_2014-02.csv\n",
      "fp ../data\\yellow_tripdata_2014-02.csv\n",
      "fn yellow_tripdata_2014-03.csv\n",
      "fp ../data\\yellow_tripdata_2014-03.csv\n",
      "fn yellow_tripdata_2014-04.csv\n",
      "fp ../data\\yellow_tripdata_2014-04.csv\n",
      "fn yellow_tripdata_2014-05.csv\n",
      "fp ../data\\yellow_tripdata_2014-05.csv\n",
      "fn yellow_tripdata_2014-06.csv\n",
      "fp ../data\\yellow_tripdata_2014-06.csv\n",
      "fn yellow_tripdata_2014-07.csv\n",
      "fp ../data\\yellow_tripdata_2014-07.csv\n",
      "fn yellow_tripdata_2014-08.csv\n",
      "fp ../data\\yellow_tripdata_2014-08.csv\n",
      "fn yellow_tripdata_2014-09.csv\n",
      "fp ../data\\yellow_tripdata_2014-09.csv\n",
      "fn yellow_tripdata_2014-10.csv\n",
      "fp ../data\\yellow_tripdata_2014-10.csv\n",
      "fn yellow_tripdata_2014-11.csv\n",
      "fp ../data\\yellow_tripdata_2014-11.csv\n",
      "fn yellow_tripdata_2014-12.csv\n",
      "fp ../data\\yellow_tripdata_2014-12.csv\n",
      "fn yellow_tripdata_2015-01.csv\n",
      "fp ../data\\yellow_tripdata_2015-01.csv\n",
      "fn yellow_tripdata_2015-02.csv\n",
      "fp ../data\\yellow_tripdata_2015-02.csv\n",
      "fn yellow_tripdata_2015-03.csv\n",
      "fp ../data\\yellow_tripdata_2015-03.csv\n",
      "fn yellow_tripdata_2015-04.csv\n",
      "fp ../data\\yellow_tripdata_2015-04.csv\n",
      "fn yellow_tripdata_2015-05.csv\n",
      "fp ../data\\yellow_tripdata_2015-05.csv\n",
      "fn yellow_tripdata_2015-06.csv\n",
      "fp ../data\\yellow_tripdata_2015-06.csv\n",
      "fn yellow_tripdata_2015-07.csv\n",
      "fp ../data\\yellow_tripdata_2015-07.csv\n",
      "fn yellow_tripdata_2015-08.csv\n",
      "fp ../data\\yellow_tripdata_2015-08.csv\n",
      "fn yellow_tripdata_2015-09.csv\n",
      "fp ../data\\yellow_tripdata_2015-09.csv\n",
      "fn yellow_tripdata_2015-10.csv\n",
      "fp ../data\\yellow_tripdata_2015-10.csv\n",
      "fn yellow_tripdata_2015-11.csv\n",
      "fp ../data\\yellow_tripdata_2015-11.csv\n",
      "fn yellow_tripdata_2015-12.csv\n",
      "fp ../data\\yellow_tripdata_2015-12.csv\n",
      "fn yellow_tripdata_2016-01.csv\n",
      "fp ../data\\yellow_tripdata_2016-01.csv\n",
      "fn yellow_tripdata_2016-02.csv\n",
      "fp ../data\\yellow_tripdata_2016-02.csv\n",
      "fn yellow_tripdata_2016-03.csv\n",
      "fp ../data\\yellow_tripdata_2016-03.csv\n",
      "fn yellow_tripdata_2016-04.csv\n",
      "fp ../data\\yellow_tripdata_2016-04.csv\n",
      "fn yellow_tripdata_2016-05.csv\n",
      "fp ../data\\yellow_tripdata_2016-05.csv\n",
      "fn yellow_tripdata_2016-06.csv\n",
      "fp ../data\\yellow_tripdata_2016-06.csv\n",
      "fn yellow_tripdata_2016-07.csv\n",
      "fp ../data\\yellow_tripdata_2016-07.csv\n",
      "fn yellow_tripdata_2016-08.csv\n",
      "fp ../data\\yellow_tripdata_2016-08.csv\n",
      "fn yellow_tripdata_2016-09.csv\n",
      "fp ../data\\yellow_tripdata_2016-09.csv\n",
      "fn yellow_tripdata_2016-10.csv\n",
      "fp ../data\\yellow_tripdata_2016-10.csv\n",
      "fn yellow_tripdata_2016-11.csv\n",
      "fp ../data\\yellow_tripdata_2016-11.csv\n",
      "fn yellow_tripdata_2016-12.csv\n",
      "fp ../data\\yellow_tripdata_2016-12.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('../data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('../data', fn)\n",
    "        print('fn', fn)\n",
    "        print('fp', fp)\n",
    "        r = requests.get(url)\n",
    "        with open(fp, 'wb') as outFile:\n",
    "            outFile.write(r.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glob 라이브러리에 포함된 glob메서드는 특정한 패턴의 이름을 가진 파일을 한 번에 읽어 들일 수 있다.\n",
    "### 폴더에서 fhv_로 시작하는 파일들의 데이터를 한번에 불러들이기\n",
    "- ex) import glob\n",
    "-     nyc_taxi_data = glob.glob('../data/fhv_*')\n",
    "-     print(nyc_taxi_data)\n",
    "- ********************************************\n",
    "- output) ['../data\\\\fhv_tropdata_2015)01.csv',\n",
    "-          '../data\\\\fhv_tropdata_2015)02.csv',\n",
    "-           '../data\\\\fhv_tropdata_2015)03.csv',\n",
    "-           '../data\\\\fhv_tropdata_2015)04.csv',\n",
    "-           '../data\\\\fhv_tropdata_2015)05.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그럼다음 각각의 파일을 데이터 프레임으로 pandas를 이용하여 넣어준다.\n",
    "- taxi1 = pd.read.csv(nyc_taxi_data[0])\n",
    "- taxi2 = pd.read.csv(nyc_taxi_data[1])\n",
    "- taxi3 = pd.read.csv(nyc_taxi_data[2])\n",
    "- taxi4 = pd.read.csv(nyc_taxi_data[3])\n",
    "- taxi5 = pd.read.csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복문으로 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
