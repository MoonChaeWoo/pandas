{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분석하기 좋은데이터 (Tidy data)\n",
    "### 깔끔한 데이터의 조건\n",
    "- 데이터 분석 목적에 맞는 데이터를 모아 새로운 표를 만들어야 한다.\n",
    "- 측정한 값은 행(row)을 구성해야 한다.\n",
    "- 변수는 열(columns)로 구성해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../data/concat_1.csv')\n",
    "df2 = pd.read_csv('../data/concat_2.csv')\n",
    "df3 = pd.read_csv('../data/concat_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "    A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "     A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df = [df1, df2, df3]\n",
    "for i in range(3):\n",
    "    print(df[i])\n",
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat 메서드에 연결하려는 데이터 프레임을 리스트에 담아 전달하면 연결한 데이터프레임을 반환한다.\n",
    "### concat 메서드는 데이터프레임을 연결할 때 위에서 아래 방향으로 연결한다.\n",
    "### df1,2,3,4 모두 열의 이름이 ABCD로 같다. 그래서 데이터 프레임을 연결한 다음에도 열이 그대로 유지된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(row_concat.iloc[3 ,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임에 시리즈 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row_series = pd.Series(['n1','n2','n3','n4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series를 추가하면 새로운 행으로 추가될 거 같지만 새로운 열이 추가되어 NAN(누락값)이 많이 발생하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행 1개로 구성된 데이터프레임 생성하여 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 방법으로 데이터 연결하기\n",
    "- 행이 1개라도 반드시 데이터프레임에 담아 연결해야한다.\n",
    "- 시리즈를 데이터프레임의 새로운 행으로 연결하려면 제대로 되지 않는다.\n",
    "- 시리즈에는 열 이름이 없기 때문이다.\n",
    "- 위에서 concat으로 합친 시리즈를 새로운 열로 간주하여 0이라는 이름으로 자동으로 추가가 된것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_row_df0\n",
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "------------------------------------------------------------\n",
      "new_row_df1\n",
      "    A\n",
      "0  n1\n",
      "1  n2\n",
      "2  n3\n",
      "3  n4\n",
      "------------------------------------------------------------\n",
      "new_row_df2\n",
      "  n1 n2\n",
      "0  1  4\n",
      "1  2  3\n",
      "2  3  2\n",
      "3  4  1\n",
      "------------------------------------------------------------\n",
      "new_row_df3\n",
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "------------------------------------------------------------\n",
      "pd.concat([df1, new_row_df3])\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_row_df0 = pd.DataFrame([['n1','n2','n3','n4']], columns=['A','B','C','D'])\n",
    "new_row_df1 = pd.DataFrame(['n1','n2','n3','n4'], columns=['A'])\n",
    "print('new_row_df0')\n",
    "print(new_row_df0)\n",
    "print('-'*60)\n",
    "print('new_row_df1')\n",
    "print(new_row_df1)\n",
    "print('-'*60)\n",
    "\n",
    "new_row_df2 = pd.DataFrame({\n",
    "    'n1' : ['1','2','3','4'],\n",
    "    'n2' : ['4','3','2','1']\n",
    "},\n",
    "index = ['0', '1', '2', '3'])\n",
    "print('new_row_df2')\n",
    "print(new_row_df2)\n",
    "print('-'*60)\n",
    "\n",
    "new_row_df3 = pd.DataFrame({\n",
    "    'A' : ['n1'],\n",
    "    'B' : ['n2'],\n",
    "    'C' : ['n3'],\n",
    "    'D' : ['n4']\n",
    "},\n",
    "index = ['0'])\n",
    "print('new_row_df3')\n",
    "print(new_row_df3)\n",
    "print('-'*60)\n",
    "print('pd.concat([df1, new_row_df3])')\n",
    "print(pd.concat([df1, new_row_df3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_row\n",
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "------------------------------------------------------------------------------------------\n",
      "    A\n",
      "0  n1\n",
      "1  n2\n",
      "2  n3\n",
      "3  n4\n",
      "------------------------------------------------------------------------------------------\n",
      "   n1  n2\n",
      "0   1   4\n",
      "1   2   3\n",
      "2   3   2\n",
      "3   4   1\n",
      "------------------------------------------------------------------------------------------\n",
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "------------------------------------------------------------------------------------------\n",
      "    A    B    C    D\n",
      "0  a1  a11  a22  a31\n",
      "1  a2  a12  a22  a32\n",
      "2  a3  a13  a23  a33\n",
      "3  a4  a14  a24  a34\n",
      "------------------------------------------------------------------------------------------\n",
      "    A    B    C    D\n",
      "0  a0   b0   c0   d0\n",
      "1  a1   b1   c1   d1\n",
      "2  a2   b2   c2   d2\n",
      "3  a3   b3   c3   d3\n",
      "0  a1  a11  a22  a31\n",
      "1  a2  a12  a22  a32\n",
      "2  a3  a13  a23  a33\n",
      "3  a4  a14  a24  a34\n"
     ]
    }
   ],
   "source": [
    "test_row = pd.DataFrame([['n1','n2','n3','n4']], columns=['A','B','C','D'])\n",
    "print('test_row')\n",
    "print(test_row)\n",
    "print('-'*90)\n",
    "test_row = pd.DataFrame(['n1','n2','n3','n4'], columns=['A'])\n",
    "print(test_row)\n",
    "print('-'*90)\n",
    "\n",
    "test_row = pd.DataFrame([[1,4],[2,3],[3,2],[4,1]], columns=['n1', 'n2'])\n",
    "print(test_row)\n",
    "print('-'*90)\n",
    "\n",
    "test_row = pd.DataFrame({\n",
    "    'A' : ['n1'],\n",
    "    'B' : ['n2'],\n",
    "    'C' : ['n3'],\n",
    "    'D' : ['n4'],\n",
    "},\n",
    "index=[0])\n",
    "print(test_row)\n",
    "print('-'*90)\n",
    "\n",
    "test_row = pd.DataFrame({\n",
    "    'A' : ['a1','a2','a3','a4'],\n",
    "    'B' : ['a11','a12','a13','a14'],\n",
    "    'C' : ['a22','a22','a23','a24'],\n",
    "    'D' : ['a31','a32','a33','a34'],\n",
    "},\n",
    "index=[0,1,2,3])\n",
    "print(test_row)\n",
    "print('-'*90)\n",
    "print(pd.concat([df1, test_row]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat\n",
    "-  한번에 2개 이상의 데이터프레임을 연결할 수 있는 메서드\n",
    "\n",
    "# append\n",
    "- 연결할 데이터가 1개라면 append메서드를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16984\\3846122007.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  print(df1.append(single_dat))\n"
     ]
    }
   ],
   "source": [
    "single_dat = pd.DataFrame([['n1','n2','n3','n4']], columns = ['A','B','C','D'])\n",
    "\n",
    "print(df1.append(single_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16984\\2893272526.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  print(df1.append(data_dict, ignore_index=True))\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'A' : 'n1','B' : 'n2','C' : 'n3','D' : 'n4',}\n",
    "print(df1.append(data_dict, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ignore_index를 True로 지정하면 데이터를 연결한 다음 데이터프레임의 인덱스를 0부터 다시 지정하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n",
      "------------------------------------------------------------\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, single_dat]))\n",
    "print('-'*60)\n",
    "print(pd.concat([df1, single_dat], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 열 방향으로 연결하기  axis=1 또는 변수.concat['추가할 열 이름'] = ['값']\n",
    "- 행 방향이 아닌 열 방향으로 데이터를 연결하려면 concat의 메서드의 axis의 인자를 1로 지정하면 된다.\n",
    "\n",
    "- 다음 예시로 d1, d2, d3, d4를 열 방향으로 연결해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axix = 1\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n",
      "------------------------------------------------------------------------------------------\n",
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n",
      "------------------------------------------------------------------------------------------\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_concat\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8             n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9             n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10             n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11             n4\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "col_concat = pd.concat([df1,df2,df3], axis=1, ignore_index=True)\n",
      "행이 중복되었기에 ignore_index=True를 주어 열 이름을 다시 지정해주었다.\n",
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "axix = 0, default\n",
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n",
      "------------------------------------------------------------------------------------------\n",
      "0      a0\n",
      "1      a1\n",
      "2      a2\n",
      "3      a3\n",
      "4      a4\n",
      "5      a5\n",
      "6      a6\n",
      "7      a7\n",
      "8      a8\n",
      "9      a9\n",
      "10    a10\n",
      "11    a11\n",
      "Name: A, dtype: object\n",
      "------------------------------------------------------------------------------------------\n",
      "      A    B    C    D new_col_concat\n",
      "0    a0   b0   c0   d0             n1\n",
      "1    a1   b1   c1   d1             n2\n",
      "2    a2   b2   c2   d2             n3\n",
      "3    a3   b3   c3   d3             n4\n",
      "4    a4   b4   c4   d4             n5\n",
      "5    a5   b5   c5   d5             n6\n",
      "6    a6   b6   c6   d6             n7\n",
      "7    a7   b7   c7   d7             n8\n",
      "8    a8   b8   c8   d8             n9\n",
      "9    a9   b9   c9   d9            n10\n",
      "10  a10  b10  c10  d10            n11\n",
      "11  a11  b11  c11  d11            n12\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "print('axix = 1')\n",
    "print(col_concat)\n",
    "print('-'*90)\n",
    "print(col_concat['A'])\n",
    "print('-'*90)\n",
    "col_concat['new_col_concat']=['n1','n2','n3','n4']\n",
    "print(col_concat)\n",
    "print('*'*90)\n",
    "print('*'*90)\n",
    "print('*'*90)\n",
    "print('col_concat = pd.concat([df1,df2,df3], axis=1, ignore_index=True)')\n",
    "print('행이 중복되었기에 ignore_index=True를 주어 열 이름을 다시 지정해주었다.')\n",
    "col_concat = pd.concat([df1,df2,df3], axis=1, ignore_index=True)\n",
    "print(col_concat)\n",
    "print('*'*90)\n",
    "print('*'*90)\n",
    "print('*'*90)\n",
    "col_concat = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print('axix = 0, default')\n",
    "print(col_concat)\n",
    "print('-'*90)\n",
    "print(col_concat['A'])\n",
    "print('-'*90)\n",
    "col_concat['new_col_concat']=['n1','n2','n3','n4','n5','n6','n7','n8','n9','n10','n11','n12',]\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공통 열과 공통 인덱스만 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Index(['E', 'F', 'G', 'H'], dtype='object')\n",
      "Index(['A', 'C', 'F', 'H'], dtype='object')\n",
      "------------------------------------------------------------\n",
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Index(['E', 'F', 'G', 'H'], dtype='object')\n",
      "Index(['A', 'C', 'F', 'H'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(df[i].columns)\n",
    "    \n",
    "print('-'*60)\n",
    "df2.columns = ['E','F','G','H']\n",
    "df3.columns = ['A','C','F','H']\n",
    "\n",
    "df = [df1, df2, df3]\n",
    "for i in range(3):\n",
    "    print(df[i].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D    E    F    G    H\n",
      "0    a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1    a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2    a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3    a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "4   NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "5   NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "6   NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "7   NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "8    a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "9    a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "10  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "11  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n",
      "------------------------------------------------------------\n",
      "    A   B   C   D   E   F   G   H    A    C    F    H\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "print(row_concat)\n",
    "print('-'*60)\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3], axis =1)\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join에 인자로 'inner'을 넣어주면 공통 열만 연결하여 연결해준다.\n",
    "- 공통된게 없다면 Empty DataFrame가 나온다.\n",
    "- outer가 default이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Index(['A', 'C', 'F', 'H'], dtype='object')\n",
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "print(df3.columns)\n",
    "print(pd.concat([df1, df3], join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "------------------------------------------------------------------------------------------\n",
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n",
      "------------------------------------------------------------------------------------------\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "df1.index = [0, 1, 2, 3]\n",
    "df2.index = [4, 5, 6, 7]\n",
    "df3.index = [0, 2, 5, 7]\n",
    "\n",
    "print(df1)\n",
    "print('-'*90)\n",
    "print(df2)\n",
    "print('-'*90)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df3], axis=1, join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge 메서드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n"
     ]
    }
   ],
   "source": [
    "person = pd.read_csv('../data/survey_person.csv')\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n"
     ]
    }
   ],
   "source": [
    "site = pd.read_csv('../data/survey_site.csv')\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "survey = pd.read_csv('../data/survey_survey.csv')\n",
    "print(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "visited = pd.read_csv('../data/survey_visited.csv')\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "2    734   DR-3  1939-01-07\n",
      "6    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "visited_subset = visited.loc[[0, 2, 6],]\n",
    "print(visited_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge 메서드는 기본적으로 내부 조인을 실행한다.\n",
    "- 메서드를 사용한 데이터 프레임을 왼쪽으로 지정한다.\n",
    "- 첫 번째 인잣값으로 지정한 데이터프레임을 오른쪽으로 지정한다.\n",
    "- left_on, right_on 인자는 값이 일치해야 할 왼쪽과 오른쪽 데이터프레임의 열을 지정한다.\n",
    "- 즉 왼쪽 데이터프레임의 열과 오른쪽 데이터프레임의 열의 값이 일치하면 왼쪽 데이터프레임을 기준으로 연결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "------------------------------------------------------------\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "2    734   DR-3  1939-01-07\n",
      "6    837  MSK-4  1932-01-14\n",
      "------------------------------------------------------------\n",
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "o2o_merge = site.merge(visited_subset, left_on='name', right_on='site')\n",
    "print(site)\n",
    "print('-'*60)\n",
    "print(visited_subset)\n",
    "print('-'*60)\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'lat', 'long'], dtype='object')\n",
      "(3, 3)\n",
      "Index(['ident', 'site', 'dated'], dtype='object')\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "print(site.columns)\n",
    "print(site.shape)\n",
    "print(visited.columns)\n",
    "print(visited.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "------------------------------------------------------------\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "print(site)\n",
    "print('-'*60)\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "o2o_merge = site.merge(visited, left_on='name', right_on='site')\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n",
      "------------------------------------------------------------\n",
      "survey\n",
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n",
      "------------------------------------------------------------\n",
      "visited\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "print('person')\n",
    "print(person)\n",
    "print('-'*60)\n",
    "print('survey')\n",
    "print(survey)\n",
    "print('-'*60)\n",
    "print('visited')\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     619\n",
      "1     619\n",
      "2     622\n",
      "3     622\n",
      "4     734\n",
      "5     734\n",
      "6     734\n",
      "7     735\n",
      "8     735\n",
      "9     735\n",
      "10    751\n",
      "11    751\n",
      "12    751\n",
      "13    752\n",
      "14    752\n",
      "15    752\n",
      "16    752\n",
      "17    837\n",
      "18    837\n",
      "19    837\n",
      "20    844\n",
      "21    619\n",
      "22    622\n",
      "23    734\n",
      "24    735\n",
      "25    751\n",
      "26    752\n",
      "27    837\n",
      "28    844\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([survey['taken'], visited['ident']], join='inner', ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
